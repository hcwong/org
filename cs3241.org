#+TITLE: CS3241
#+AUTHOR: Joshua Wong

This course focuses on 3D computer graphics, but graphics deals with creating images with a computer, using applications, software and hardware.

* Lecture 1
** Display Processor
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_1.png]]

Expensive to have host computer refresh display, so use special purpose computer called display processor (DPU)

Graphics stored in display list on display processor
Host compiles display list and sends to DPU

** Raster Graphics and OpenGL
Image produced as an array (the raster) of pixels in frame buffer

Then came OpenGL API after that

** Image Formation
In computer graphics, 2D images are formed like how they would in cameras and eyes.

*** Elements of Image Formation
1. Objects
2. Light
   - For humans, only care about RGB for luminance images. For monochromatic, only values are grey values
   - There are two types of color: Additive and Subtractive. Additive is formed via RGBs. Subtractive is via filtering white light with Cyan, Magenta and Yellow
3. Viewer
4. Material

#+NAME: Pinhole camera
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_2.png]]

#+NAME: Synthetic camera
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_3.png]]

This paradigm looks at creating a computer generated image as being similar to forming an image using an optical system.

*** Advantages of Synthetic Camera system
The advantages of such synthetic camera model is the separation of objects viewers and light sources -> simpler API.

Image is also not moved to infront of the camera

** Lighting
Lighting of objects cannot be calculated independently as light can reflect, and some objects are also blocked from light or are translucent.

** Image Formation Model

The API mimics the synthetic camera model to design graphics hardware & software.

For the API, we only need to specify: Objects, materials, viewer and lights

*** Physical approaches
Ray Tracing - follow rays of light from center of projection until they are absorbed by objects or go off course. It can handle global effects but is slow and must keep whole database available

Radiosity - Energy based approach that is slow and not general.

*** Practical Approach for Real-Time rendering
#+NAME: Pipeline architecture
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_4.png]]

All this steps can be implemented in graphics hardware

**** Vertex Processing
Converting object representations from one coordinate system to another (object, synthetic camera, screen coords) via matrix transformations.

Vertex processor also computes lighting.

**** Projection
This is the process that combines the 3D viewer with the 3D objects to priuce 2D image.

Two kinds: Perspective projection where all projectors meet at the center of the projection.
Parallel where the projectors are parallel and center of projection is replaced with a direction of projection.

**** Primitive Assembly
Vertices must be collected into geometric objects and primitives before clipping and rasterization can take place. So stuff like lines, polygons, curves

**** Clipping
A camera can only see the part of the world within the object space, so things not within this space are clipped out via a series of panes.

#+NAME: Clipping
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_5.png]]

**** Rasterization
Applies color to the appropriate pixels in the frame buffer.

For each object, the rasterizer produces a set of *fragments* for each object. *Fragments* are potential pixels and they have a location in frame buffer, color and depth attributes.

Vertex attributes are interpolated over the vertex objects by the rasterizer

**** Fragment Processing
Fragments are processed to determine color of corresponding pixel in frame buffer. Colors are determined by *texture mapping* or interpolation of vertex colors.

Fragments can also be blocked by fragments closer to camera and this is removed (hidden surface removal)

*** Programmer's interface
This system is exposed via the graphics library API

It exposes functions that specify what is needed to form an image

- Objects
- Viewer
- Light Source
- Material
- Other info like device input and system capabilities

APIs also support a limited set of primitives like points (0D), lines (1D), polygons (2D), curves and surfaces. All these are defined through locations in space or vertices.

#+BEGIN_SRC cpp
glBegin(GL_POLYGON); // type of object
  glVertex3f(0.0, 0.0, 0.0); // location of vertex
  glVertex3f(0.0, 1.0, 0.0);
  glVertex3f(0.0, 0.0, 1.0);
gl.End(); // end of obj definition
#+END_SRC

*** Camera Specification
#+NAME: Camera Specification
#+ATTR_ORG: :width 600
[[file:images/cs3241_l1_6.png]]

*** Lights and Materials
Types of light and material property (absorption, diffuse vs specular scattering) also matter
